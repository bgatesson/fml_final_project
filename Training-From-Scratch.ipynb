{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89845ca6-3747-4bf8-9eb1-2c56a8cd74af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"bitcoin_sentiments_21_24_cleaned.csv\")\n",
    "\n",
    "data_text = list(dataset['Cleaned_Description'])\n",
    "dates = list(dataset['Date'])\n",
    "labels = list(dataset['Sentiment_Category'])\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "235656ad-61e7-4a4e-a48d-3a81f0c07914",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, dates, labels, tokenizer, max_length=64):\n",
    "        self.labels = labels\n",
    "        self.texts = texts\n",
    "        self.encodings = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        self.dates = dates\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return a dictionary with input_ids, attention_mask, etc.\n",
    "        item = {\n",
    "            \"input_ids\": self.encodings[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n",
    "            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
    "            \"date\": self.dates[idx],\n",
    "            \"text\": self.texts[idx]\n",
    "        }\n",
    "        # token_type_ids are also available if needed\n",
    "        return item\n",
    "\n",
    "\n",
    "dataset = SentimentDataset(data_text, dates, labels, tokenizer, max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e9c9b06-7c38-42a7-ae9d-154c837dfa63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  2978,  3597,  2378,  3976,  2003,  9530, 19454,  8524,  3436,\n",
       "          2379,  1996, 13751, 23612,  8889,  2490, 28855, 14820,  2003,  3173,\n",
       "         12154,  2682, 13751,  3429, 12376,  1060, 14536,  2453,  6149,  2896,\n",
       "          2000, 13751, 10630,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'label': tensor(0),\n",
       " 'date': '2021-11-05 04:42:00',\n",
       " 'text': 'Bitcoin price is consolidating near the USD 62000 support Ethereum is holding gains above USD 4550 XRP might correct lower to USD 115'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be59a86f-c31d-4930-9d13-b974aef8c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "val_size = int(0.1 * len(dataset))    # 10% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # Remaining 10% for testing\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275cdd54-8e00-432d-ace8-539c34f510cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_embeddings(glove_file, embedding_dim):\n",
    "    embeddings_index = {}\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f, start=1):\n",
    "            # Strip and split\n",
    "            values = line.strip().split()\n",
    "            \n",
    "            # Quick check: does the line have the right number of elements?\n",
    "            if len(values) != embedding_dim + 1:\n",
    "                # If not, skip or print a warning\n",
    "                print(f\"Skipping line {line_num}: expected {embedding_dim+1} elements, found {len(values)}\")\n",
    "                continue\n",
    "            \n",
    "            word = values[0]\n",
    "            try:\n",
    "                coefs = np.asarray(values[1:], dtype='float32')\n",
    "            except ValueError as e:\n",
    "                # If conversion fails, skip this line or handle the error\n",
    "                print(f\"Skipping line {line_num} due to parse error: {e}\")\n",
    "                continue\n",
    "            \n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b8e12-f041-4c1b-a412-ad4f561a23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = \"glove.840B.300d.txt\"\n",
    "embedding_dim = 300\n",
    "embeddings_index = load_pretrained_embeddings(glove_file, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff3899d-2ba5-4f39-a150-2e60cfdca429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_matrix(vocab_size, embeddings_index, embedding_dim):\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim), dtype='float32')\n",
    "    \n",
    "    for word, i in word_to_idx.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[i] = embeddings_index[word]\n",
    "        else:\n",
    "            # If not found, could be random or zero\n",
    "            embedding_matrix[i] = np.random.normal(scale=0.6, size=(embedding_dim,))\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b11923b-9c26-4769-8e01-436a6a918a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to output hidden layers to classifier now changed to Attention Layer\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, num_classes=3, pretrained_emb=None, freeze_embedding=False):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        if pretrained_emb is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                embeddings=pretrained_emb, \n",
    "                freeze=freeze_embedding  # If True, embeddings are not updated\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        # 2) An LSTM\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=2, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.attention = nn.Linear(hidden_dim*2, 1, bias=False)\n",
    "        \n",
    "        # 3) Linear classifier for 3 classes\n",
    "        self.classifier = nn.Linear(hidden_dim*2, num_classes)\n",
    "\n",
    "        # Optional dropout\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        # input_ids: [batch_size, seq_len]\n",
    "        # attention_mask: [batch_size, seq_len]\n",
    "\n",
    "        # Embed tokens\n",
    "        embedded = self.embedding(input_ids)  # [batch_size, seq_len, embed_dim]\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # LSTM\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        \n",
    "        attn_scores = self.attention(outputs)\n",
    "        if attention_mask is not None:\n",
    "            # Convert attention_mask to float so we can do arithmetic\n",
    "            # We can set pad positions to a large negative number to zero out their influence.\n",
    "            mask = attention_mask.unsqueeze(-1)  # [batch_size, seq_len, 1]\n",
    "            # Where mask=0 => we set scores to a large negative\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "        context_vector = torch.sum(outputs * attn_weights, dim=1)\n",
    "\n",
    "        # Classifier => [batch_size, num_classes]\n",
    "        logits = self.classifier(context_vector)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061ae12d-d1cb-498f-9c10-27442d47220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# glove_file = \"glove.840B.300d.txt\"\n",
    "# embedding_dim = 300\n",
    "# embeddings_index = load_pretrained_embeddings(glove_file, embedding_dim)\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "# embedding_matrix_np = build_embedding_matrix(vocab_size, embeddings_index, embedding_dim)\n",
    "# embedding_matrix = torch.FloatTensor(embedding_matrix_np)\n",
    "\n",
    "model = LSTMModel(\n",
    "    vocab_size=vocab_size,\n",
    "    #embed_dim=embedding_dim,\n",
    "    hidden_dim=128,\n",
    "    num_classes=3,\n",
    "    #pretrained_emb=embedding_matrix,\n",
    "    #freeze_embedding=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2268c401-eaf7-4d72-8121-93ab2f4f77a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6bc8e97-c99a-48a2-a07c-dcd8daf68017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.0790\n",
      "Epoch [2/100], Loss: 1.0352\n",
      "Epoch [3/100], Loss: 0.9945\n",
      "Epoch [4/100], Loss: 0.9730\n",
      "Epoch [5/100], Loss: 0.9675\n",
      "Validation - Epoch [5/100], Loss: 0.9177, Accuracy: 0.5600\n",
      "Epoch [6/100], Loss: 0.9558\n",
      "Epoch [7/100], Loss: 0.9398\n",
      "Epoch [8/100], Loss: 0.9306\n",
      "Epoch [9/100], Loss: 0.9183\n",
      "Epoch [10/100], Loss: 0.9121\n",
      "Validation - Epoch [10/100], Loss: 0.8992, Accuracy: 0.5855\n",
      "Epoch [11/100], Loss: 0.8949\n",
      "Epoch [12/100], Loss: 0.8856\n",
      "Epoch [13/100], Loss: 0.8747\n",
      "Epoch [14/100], Loss: 0.8687\n",
      "Epoch [15/100], Loss: 0.8631\n",
      "Validation - Epoch [15/100], Loss: 0.8487, Accuracy: 0.6091\n",
      "Epoch [16/100], Loss: 0.8531\n",
      "Epoch [17/100], Loss: 0.8497\n",
      "Epoch [18/100], Loss: 0.8340\n",
      "Epoch [19/100], Loss: 0.8310\n",
      "Epoch [20/100], Loss: 0.8165\n",
      "Validation - Epoch [20/100], Loss: 0.8752, Accuracy: 0.6145\n",
      "Epoch [21/100], Loss: 0.8080\n",
      "Epoch [22/100], Loss: 0.8013\n",
      "Epoch [23/100], Loss: 0.7917\n",
      "Epoch [24/100], Loss: 0.7812\n",
      "Epoch [25/100], Loss: 0.7850\n",
      "Validation - Epoch [25/100], Loss: 0.8280, Accuracy: 0.6373\n",
      "Epoch [26/100], Loss: 0.7786\n",
      "Epoch [27/100], Loss: 0.7722\n",
      "Epoch [28/100], Loss: 0.7675\n",
      "Epoch [29/100], Loss: 0.7591\n",
      "Epoch [30/100], Loss: 0.7520\n",
      "Validation - Epoch [30/100], Loss: 0.8091, Accuracy: 0.6527\n",
      "Epoch [31/100], Loss: 0.7428\n",
      "Epoch [32/100], Loss: 0.7389\n",
      "Epoch [33/100], Loss: 0.7311\n",
      "Epoch [34/100], Loss: 0.7253\n",
      "Epoch [35/100], Loss: 0.7214\n",
      "Validation - Epoch [35/100], Loss: 0.7810, Accuracy: 0.6645\n",
      "Epoch [36/100], Loss: 0.7130\n",
      "Epoch [37/100], Loss: 0.7087\n",
      "Epoch [38/100], Loss: 0.7032\n",
      "Epoch [39/100], Loss: 0.6938\n",
      "Epoch [40/100], Loss: 0.6846\n",
      "Validation - Epoch [40/100], Loss: 0.8128, Accuracy: 0.6673\n",
      "Epoch [41/100], Loss: 0.6925\n",
      "Epoch [42/100], Loss: 0.6786\n",
      "Epoch [43/100], Loss: 0.6654\n",
      "Epoch [44/100], Loss: 0.6657\n",
      "Epoch [45/100], Loss: 0.6633\n",
      "Validation - Epoch [45/100], Loss: 0.7813, Accuracy: 0.6782\n",
      "Epoch [46/100], Loss: 0.6609\n",
      "Epoch [47/100], Loss: 0.6569\n",
      "Epoch [48/100], Loss: 0.6458\n",
      "Epoch [49/100], Loss: 0.6450\n",
      "Epoch [50/100], Loss: 0.6357\n",
      "Validation - Epoch [50/100], Loss: 0.7728, Accuracy: 0.6818\n",
      "Epoch [51/100], Loss: 0.6315\n",
      "Epoch [52/100], Loss: 0.6298\n",
      "Epoch [53/100], Loss: 0.6292\n",
      "Epoch [54/100], Loss: 0.6223\n",
      "Epoch [55/100], Loss: 0.6234\n",
      "Validation - Epoch [55/100], Loss: 0.7556, Accuracy: 0.6836\n",
      "Epoch [56/100], Loss: 0.6126\n",
      "Epoch [57/100], Loss: 0.6179\n",
      "Epoch [58/100], Loss: 0.5985\n",
      "Epoch [59/100], Loss: 0.6035\n",
      "Epoch [60/100], Loss: 0.5955\n",
      "Validation - Epoch [60/100], Loss: 0.7652, Accuracy: 0.6755\n",
      "Epoch [61/100], Loss: 0.5911\n",
      "Epoch [62/100], Loss: 0.5886\n",
      "Epoch [63/100], Loss: 0.5799\n",
      "Epoch [64/100], Loss: 0.5845\n",
      "Epoch [65/100], Loss: 0.5823\n",
      "Validation - Epoch [65/100], Loss: 0.7903, Accuracy: 0.6973\n",
      "Epoch [66/100], Loss: 0.5776\n",
      "Epoch [67/100], Loss: 0.5702\n",
      "Epoch [68/100], Loss: 0.5720\n",
      "Epoch [69/100], Loss: 0.5705\n",
      "Epoch [70/100], Loss: 0.5698\n",
      "Validation - Epoch [70/100], Loss: 0.7543, Accuracy: 0.7045\n",
      "Epoch [71/100], Loss: 0.5604\n",
      "Epoch [72/100], Loss: 0.5543\n",
      "Epoch [73/100], Loss: 0.5580\n",
      "Epoch [74/100], Loss: 0.5562\n",
      "Epoch [75/100], Loss: 0.5447\n",
      "Validation - Epoch [75/100], Loss: 0.7540, Accuracy: 0.6936\n",
      "Epoch [76/100], Loss: 0.5266\n",
      "Epoch [77/100], Loss: 0.5326\n",
      "Epoch [78/100], Loss: 0.5391\n",
      "Epoch [79/100], Loss: 0.5259\n",
      "Epoch [80/100], Loss: 0.5227\n",
      "Validation - Epoch [80/100], Loss: 0.7565, Accuracy: 0.6955\n",
      "Epoch [81/100], Loss: 0.5242\n",
      "Epoch [82/100], Loss: 0.5158\n",
      "Epoch [83/100], Loss: 0.5135\n",
      "Epoch [84/100], Loss: 0.5150\n",
      "Epoch [85/100], Loss: 0.5064\n",
      "Validation - Epoch [85/100], Loss: 0.7531, Accuracy: 0.6982\n",
      "Epoch [86/100], Loss: 0.5099\n",
      "Epoch [87/100], Loss: 0.4972\n",
      "Epoch [88/100], Loss: 0.5042\n",
      "Epoch [89/100], Loss: 0.4969\n",
      "Epoch [90/100], Loss: 0.5018\n",
      "Validation - Epoch [90/100], Loss: 0.7611, Accuracy: 0.7073\n",
      "Epoch [91/100], Loss: 0.4919\n",
      "Epoch [92/100], Loss: 0.5025\n",
      "Epoch [93/100], Loss: 0.4880\n",
      "Epoch [94/100], Loss: 0.4818\n",
      "Epoch [95/100], Loss: 0.4853\n",
      "Validation - Epoch [95/100], Loss: 0.7683, Accuracy: 0.7064\n",
      "Epoch [96/100], Loss: 0.4805\n",
      "Epoch [97/100], Loss: 0.4840\n",
      "Epoch [98/100], Loss: 0.4708\n",
      "Epoch [99/100], Loss: 0.4716\n",
      "Epoch [100/100], Loss: 0.4637\n",
      "Validation - Epoch [100/100], Loss: 0.7857, Accuracy: 0.7045\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation for validation\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"label\"].to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                logits = model(input_ids, attention_mask=attention_mask)\n",
    "                \n",
    "                # Compute loss\n",
    "                loss = criterion(logits, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Compute accuracy\n",
    "                predictions = torch.argmax(logits, dim=-1)\n",
    "                correct += (predictions == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = correct / total\n",
    "\n",
    "        print(f\"Validation - Epoch [{epoch+1}/{epochs}], Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "        model.train()  # Switch back to training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e7dc40e-72d5-482c-9b82-92dacb6a57cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7221\n",
      "Precision: 0.7293\n",
      "Recall: 0.7089\n",
      "F1 Score: 0.7139\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_texts = []\n",
    "y_dates = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        \n",
    "        logits = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "        y_texts.extend(batch[\"text\"])\n",
    "        y_dates.extend(batch[\"date\"])\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35714d87-0720-41b7-be3a-5718fa290b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"lstm_from_scratch.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5754e165-b05f-4746-838b-53c1ae200300",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\n",
    "    'date': y_dates,\n",
    "    'text': y_texts,\n",
    "    'true_label': y_true,\n",
    "    'predicted_label': y_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c09330ca-aafc-42ba-a963-4747e395914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('lstm_from_scratch_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9e4062-835f-45e8-ab4c-cbfea1fd139d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
